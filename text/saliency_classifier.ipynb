{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(data):\n",
    "    html = \"<table style=\\\"border: 1px double black; border-collapse: collapse;\\\" cellpadding=\\\"2\\\" width=\\\"1400\\\">\"\n",
    "    for row in data:\n",
    "        html += \"<tr>\"\n",
    "        for field in row:\n",
    "            html += f\"<td style=\\\"border: 1px double black; border-collapse: collapse;\\\"><h4>{field}</h4></td>\"\n",
    "        html += \"</tr>\"\n",
    "    html += \"</table>\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    text cleaning\n",
    "    :param text: str\n",
    "    :return: str\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^а-яА-Яa-zA-Z0-9ё\\-\\\\\\@/+=_%№ ]\", \" \", text)\n",
    "    text = re.sub(r\"ё\", \"е\", text)\n",
    "    text = re.sub(\"\\-\\s+\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_hot(token_ids, vocab_size):\n",
    "    token_ids = token_ids.squeeze()\n",
    "    return torch.zeros(len(token_ids), vocab_size).scatter_(1, token_ids.unsqueeze(1), 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency(prediction_logit, token_ids_tensor_one_hot, norm=True):\n",
    "    # Back-propegate the gradient from the selected output-logit\n",
    "    prediction_logit.backward(retain_graph=True)\n",
    "\n",
    "    # token_ids_tensor_one_hot.grad is the gradient propegated to ever embedding dimension of\n",
    "    # the input tokens.\n",
    "    if norm:  # norm calculates a scalar value (L2 Norm)\n",
    "        token_importance_raw = torch.norm(token_ids_tensor_one_hot.grad, dim=1)\n",
    "        # print('token_importance_raw', token_ids_tensor_one_hot.grad.shape,\n",
    "        # np.count_nonzero(token_ids_tensor_one_hot.detach().numpy(), axis=1))\n",
    "\n",
    "        # Normalize the values so they add up to 1\n",
    "        token_importance = token_importance_raw / torch.sum(token_importance_raw)\n",
    "    else:\n",
    "        token_importance = torch.sum(token_ids_tensor_one_hot.grad, dim=1)  # Only one value, all others are zero\n",
    "\n",
    "    token_ids_tensor_one_hot.grad.data.zero_()\n",
    "    return token_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    config_name = \"DeepPavlov/rubert-base-cased-conversational\",\n",
    "    tokenizer_name = \"DeepPavlov/rubert-base-cased-conversational\",\n",
    "    model_name_or_path = \"DeepPavlov/rubert-base-cased-conversational\",\n",
    "    test_data = \"data/sentiment_data/test_examples.txt\",\n",
    "    test_labels = \"data/sentiment_data/test_labels.txt\",\n",
    "    labels = \"data/sentiment_data/labels.txt\",\n",
    "    checkpoint = \"outdir/14_0.79_sentim.pt\",\n",
    "    num_labels = 3,\n",
    "    device = \"cuda\",\n",
    "    maxlen = 128\n",
    ")"
   ]
  },
  {
   "source": [
    "# Initialize BERT model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    args.config_name if args.config_name else args.model_name_or_path,\n",
    "    num_labels=args.num_labels\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    args.tokenizer_name if args.tokenizer_name else args.model_name_or_path\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "source": [
    "# Load model from checkpoint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(args.device)\n",
    "model.load_state_dict(torch.load(args.checkpoint)[\"model_state_dict\"])\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "source": [
    "# Do prediction and calculate saliency"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saliency_scores(args, model, tokenizer, sample):\n",
    "    # prepare input\n",
    "    text = preprocess_text(sample)\n",
    "    sample_ids = tokenizer.encode(text, max_length=args.maxlen, padding=\"max_length\")\n",
    "    sample_txt = [\"[CLS]\"] + tokenizer.tokenize(text) + [\"[SEP]\"]\n",
    "    input_ids = torch.tensor(sample_ids).unsqueeze(0).to(args.device)\n",
    "\n",
    "    # do prediction and calculate saliency\n",
    "    embedding_matrix = model.bert.embeddings.word_embeddings.weight.cpu()\n",
    "    vocab_size = embedding_matrix.shape[0]\n",
    "    one_hot_tensor = _one_hot(input_ids.cpu(), vocab_size)\n",
    "    token_ids_tensor_one_hot = one_hot_tensor.clone().requires_grad_(True)\n",
    "    inputs_embeds = torch.matmul(token_ids_tensor_one_hot, embedding_matrix)\n",
    "\n",
    "    output = model(inputs_embeds=inputs_embeds.unsqueeze(0).to(args.device), output_hidden_states=True)\n",
    "    predicted_label_index = torch.argmax(output[0]).item()\n",
    "    predicted_logit = output[0][0][predicted_label_index]\n",
    "\n",
    "    saliency_scores = saliency(predicted_logit, token_ids_tensor_one_hot)\n",
    "\n",
    "    return saliency_scores, sample_txt, predicted_label_index"
   ]
  },
  {
   "source": [
    "# Show saliency for current sample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_scores, sample_txt, predicted_label_index = get_saliency_scores(args, model, tokenizer, \"Едем с Ясей и Алисой на фабрику криков))) Занятное путешествие))\")\n",
    "plot_data = [saliency_scores.numpy()[:len(sample_txt)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,1), dpi=600) \n",
    "sns.heatmap(plot_data, xticklabels=sample_txt, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[predicted_label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_scores.topk(1).indices.tolist()"
   ]
  },
  {
   "source": [
    "# Calculate top key words for each class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.test_data) as samples_file:\n",
    "    samples = samples_file.read().split(\"\\n\")\n",
    "\n",
    "with open(args.labels) as labels_file:\n",
    "    labels = labels_file.read().split(\"\\n\")\n",
    "\n",
    "classes = {}\n",
    "for sample in samples:\n",
    "    saliency_scores, sample_txt, predicted_label_index = get_saliency_scores(args, model, tokenizer, sample)\n",
    "\n",
    "    cur_label = labels[predicted_label_index]\n",
    "    cur_key_words = [sample_txt[ind] for ind in saliency_scores.topk(2).indices.tolist()]\n",
    "    \n",
    "    if cur_label not in classes.keys():\n",
    "        classes[cur_label] = {}\n",
    "\n",
    "    for key_word in cur_key_words:\n",
    "        if key_word not in classes[cur_label].keys():\n",
    "            classes[cur_label][key_word] = 1\n",
    "        else:\n",
    "            classes[cur_label][key_word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "it = 0\n",
    "for key in classes.keys():\n",
    "    data += [[key]] \n",
    "    cl = classes[key]\n",
    "\n",
    "    ordered_cl = {k: v for k, v in sorted(cl.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    for w in ordered_cl.keys():\n",
    "        if len(data[it]) < 16:\n",
    "            data[it] += [w]\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}